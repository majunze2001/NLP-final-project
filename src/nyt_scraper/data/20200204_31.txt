Twitter Moves to Target Fake Videos and Photos
Twitter, bowing to pressure from its users, said on Tuesday that it would more aggressively scrutinize fake or altered photos and videos.
Starting in March, the company said, it will add labels or take down tweets carrying manipulated images and videos. The move, while short of an outright ban, was announced one day after YouTube also said it planned to remove misleading election-related content on its site.
Twitter’s new policy highlights a balancing act — between allowing parody and removing disinformation — that social media companies face as they try to more aggressively police the content posted to their platforms.
To determine whether a tweet should be removed or labeled, Twitter said in a blog post, it will apply several tests: Is the media included with a tweet significantly altered or fabricated to mislead? Is it shared in a deceptive manner? In those cases, the tweet will probably get a label.
But if a tweet is “likely to impact public safety or cause serious harm,” it will be taken down. Twitter said it might also show a warning to people before they engaged with a tweet carrying manipulated content, or limit that tweet’s reach.
“Our approach does not focus on the specific technologies used to manipulate or fabricate media,” said Yoel Roth, Twitter’s head of site integrity. “Whether you’re using advanced machine learning tools or just slowing down a video using a 99-cent app on your phone, our focus under this policy is to look at the outcome, not how it was achieved.”
The company developed its rules after surveying more than 6,500 users, civil groups and academics, said Del Harvey, Twitter’s vice president for trust and safety.
They found that about 70 percent of surveyed Twitter users believed it was unacceptable for the company to take no action against manipulated content. More than 90 percent said such content should be removed or placed behind a warning label saying the video or image had been altered.
“Things that distort or distract from what’s happening threaten the integrity of information on Twitter,” Ms. Harvey said.
Like other social networks that have tried to crack down on bogus content, Twitter will be under pressure to consistently apply its new rules.
Samantha Bradshaw, a researcher at the Oxford Internet Institute, said that defining harm was not always clear, especially in the context of social media. “And it would be difficult to automate these responses on a global scale,” she said.
Last year, an altered video of Speaker Nancy Pelosi that made it appear that she was slurring her words spread across the internet. Another heavily edited clip of former Vice President Joseph R. Biden Jr. falsely made it seem as though he had made racist remarks.
Mr. Roth said the manipulated videos of Ms. Pelosi and Mr. Biden would get a label under Twitter’s new policy. Depending on what a tweet sharing the video said and if it caused harm, Mr. Roth said, Twitter could take the tweet down.
Last year, Twitter said it would add warning labels to hide messages from major political figures who broke the company’s rules for harassment or abuse. Normally, those tweets would be taken down, but the company argued that they would be newsworthy enough to remain on the platform. As of Tuesday, Twitter had not yet used the labels.
In January, Facebook banned “deepfake” videos from its platform. But the company said the videos of Ms. Pelosi and Mr. Biden would not be removed under the policy because they had been edited with video editing software, not artificial intelligence.
YouTube banned misleading political content on Monday as part of a new policy ahead of the presidential election in November.